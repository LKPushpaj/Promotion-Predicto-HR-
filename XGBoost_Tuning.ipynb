{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from xgboost import plot_importance\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\analyticsvidhyahackathon\\\\train_LZdllcl.csv\")\n",
    "df.set_index('employee_id',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvalidation = pd.read_csv(\"D:\\\\analyticsvidhyahackathon\\\\test_2umaH9m.csv\")\n",
    "dfvalidation.set_index('employee_id',inplace=True)\n",
    "dfvalidation['is_promoted'] = 5\n",
    "#dfvalidation.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78298, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Merging the train and test dataset\n",
    "dfmerged = pd.concat([df,dfvalidation])\n",
    "dfmerged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50684.000000\n",
       "mean         3.329256\n",
       "std          1.259993\n",
       "min          1.000000\n",
       "25%          3.000000\n",
       "50%          3.000000\n",
       "75%          4.000000\n",
       "max          5.000000\n",
       "Name: previous_year_rating, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['previous_year_rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          52399\n",
       "unique             3\n",
       "top       Bachelor's\n",
       "freq           36669\n",
       "Name: education, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filling missing enteris with maximum occuring event\n",
    "dfmerged['previous_year_rating'].fillna(3.0, inplace=True)\n",
    "dfmerged['education'].fillna('Bachelor\\'s', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    78298.000000\n",
       "mean        34.797619\n",
       "std          7.665928\n",
       "min         20.000000\n",
       "25%         29.000000\n",
       "50%         33.000000\n",
       "75%         39.000000\n",
       "max         60.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmerged['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dividing age into different bands as this company has 9 verticals and they are finding promotion for manager and below.So didvided\n",
    "###age into 4 different bands\n",
    "'''\n",
    "def findBand(age):\n",
    "    if age <=29:\n",
    "        return 1\n",
    "    elif age>29 and age<=33:\n",
    "        return 2\n",
    "    elif age>33 and age<=39:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "dfmerged['band'] = dfmerged['age'].apply(findBand)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##One hot encoding\n",
    "dfmerged = pd.concat([dfmerged[['no_of_trainings','age','previous_year_rating','length_of_service','KPIs_met >80%','awards_won?','avg_training_score','is_promoted']],\n",
    "               pd.get_dummies(dfmerged['gender'],drop_first = True),pd.get_dummies(dfmerged['education'],drop_first = True),pd.get_dummies(dfmerged['recruitment_channel'],drop_first = True),pd.get_dummies(dfmerged['department'],drop_first = True),pd.get_dummies(dfmerged['region'],drop_first = True)],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generating all possible pair of interactions between 2 pair of columns.\n",
    "##Then removing those columns \n",
    "\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "Y = dfmerged.is_promoted\n",
    "X = dfmerged.drop(['is_promoted'],1)\n",
    " \n",
    "\n",
    "\n",
    "def add_interactions(df):\n",
    "    combos = list(combinations(list(df.columns), 2))\n",
    "    colnames = list(df.columns)+['_'.join(x) for x in combos]\n",
    "    \n",
    "    #scaler = MinMaxScaler()\n",
    "    #scaler.fit(df)\n",
    "    #df = scaler.transform(df)\n",
    "    \n",
    "    poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "    df = poly.fit_transform(df)\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = colnames\n",
    "    \n",
    "    noint_indices = [i for i,x in enumerate(list((df==0).all())) if x]\n",
    "    df= df.drop(df.columns[noint_indices], axis=1)\n",
    "    \n",
    "    return df\n",
    "X = add_interactions(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78298, 830)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Seperate out the training and testing dataset\n",
    "\n",
    "X.index = Y.index\n",
    "X['is_promoted'] = Y\n",
    "\n",
    "X_validation = X[54808:]\n",
    "X = X[0:54808]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X.is_promoted\n",
    "X = X.drop(['is_promoted'],1)\n",
    " \n",
    "\n",
    "seed = 2\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Hypertune the model intensively with a 5 fold cross validation strategy.\n",
    "##first grid search for max_depth,min_child_weight then fix those and search for rest in same fashion\n",
    "### parameter scale_pos_weight is quite important in case of imbalanced dataset\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_test2b = {\n",
    "  #'min_child_weight':[5,6],\n",
    "  #'max_depth': range(3,10,2),\n",
    "  #'n_estimators':[150,200,300,400],\n",
    "  #'scale_pos_weight':[1,2,3,4],\n",
    "  #'colsample_bytree':[0.7,0.8], \n",
    "  #'subsample':[0.7,0.8],\n",
    "  #'gamma':[0,0.2.0.4]\n",
    "    \n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=150, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=3,seed=27), \n",
    " param_grid = param_test2b, scoring='f1',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2b.fit(X_train, y_train)\n",
    "print(gsearch2b.grid_scores_)\n",
    "print(\"gsearch2b.best_params_\",gsearch2b.best_params_)\n",
    "print(\"gsearch2b.best_score_\",gsearch2b.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Train the model with the best params\n",
    "modelXg = XGBClassifier(learning_rate=0.1, n_estimators=200, max_depth=4, min_child_weight=7, \n",
    "                      gamma=0.4,nthread=4, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic',scale_pos_weight=3,seed=29)\n",
    "modelXg.fit(X_train, y_train)\n",
    "y_xg = modelXg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine whether your model is overfitting or not , with the help of ROC.\n",
    "print(confusion_matrix(y_test, y_xg))\n",
    "predictions = [value for value in y_xg]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print(\"Accuracy_score: %.2f%% on test dataset\" % (accuracy * 100.0))\n",
    "print(\"precision_score: %.2f%% on test dataset\" % (precision * 100.0))\n",
    "print(\"recall_score: %.2f%% on test dataset\" % (recall * 100.0))\n",
    "print(\"f1_score: %.2f%% on test dataset\" % (f1 * 100.0))\n",
    "print(\"roc_auc test set\", roc_auc_score(y_test, model.predict_proba(X_test)[:,1]))\n",
    "print(\"roc_auc training set\", roc_auc_score(y_train, model.predict_proba(X_train)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Once the model is ready, train the model on entire dataset.\n",
    "modelXg = XGBClassifier(learning_rate=0.1, n_estimators=200, max_depth=4, min_child_weight=7, \n",
    "                      gamma=0.4,nthread=4, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic',scale_pos_weight=3,seed=29)\n",
    "\n",
    "modelXg.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##find the useful cols\n",
    "usefulcols = []\n",
    "for i in sorted( model.booster().get_fscore().items(), key=lambda x: x[1], reverse=True)[:100]:\n",
    "    usefulcols.append(i[0])\n",
    "print usefulcols\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_validation.drop(['is_promoted'],1)\n",
    "dfvalidation = X_validation.drop(['is_promoted'],1)\n",
    "y_valid = modelXg.predict(dfvalidation)\n",
    "submission = dfvalidation.copy()\n",
    "submission['is_promoted'] = y_valid\n",
    "submission['is_promoted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['is_promoted']]\n",
    "submission.reset_index(inplace=True)\n",
    "submission.to_csv(\"D:\\\\analyticsvidhyahackathon\\\\solution.csv\",index=False)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"solution_18sept.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "private = pd.read_csv(\"private_W1BajhK.csv\")\n",
    "private.columns = ['employee_id', 'actual']\n",
    "private = private.merge(sub, on = \"employee_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5346232179226069"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(private['actual'], private['is_promoted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
